// (local-set-key (kbd "s-r") (lambda () (interactive) (save-buffer) (process-send-string "*shell skm-oed*" "echo '\n'; webppl vi-bern-amortized.wppl\n")))

// show and quit
var SNQ = function(v) {
  display(v)
  process.exit()
}


var hack = {
  log: _.throttle(console.log, 300)
}


var model = function() {
  var nh = globalStore['nh'], nt = globalStore['nt']
  var weight = sample(Beta({a: 2, b: 2}),
                      {guide: function() {
                        var net = affine('recog', {in: 2, out: 2})
                        var y = T.sigmoid(net(Vector([nh, nt])));
                        // squish to (2,b)
                        var a = 2
                        var b = 50
                        var params = T.add(T.mul(y, b - a), a);
                        //hack.log(T.toScalars(ad.valueRec(params)))
                        //display(T.toScalars(y))

                        // display(nh + ',' + nt)
                        // display(T.toScalars(params))
                        // display('')

                        Beta({a: T.get(params, 0),
                              b: T.get(params, 1)})

                        // var guideMu = T.get(netOutput, 0)
                        // var guideSigma = Math.exp(T.get(netOutput, 1))
                        // return LogitNormal({a: 0.0001,
                        //                     b: 0.9999,
                        //                     mu: guideMu,
                        //                     sigma: guideSigma})

                      }})
  var score = nh * Math.log(weight) + nt * Math.log(1 - weight);
  factor(score)
  return weight
}

var numELBOSamples = 20;

var TRAIN = {
  iter: 0,
  data: null
}
var _sampleTrainingData = function() {
  return {nh: randomInteger(10) + 1,//randomInteger(30),
          nt: randomInteger(10) + 1}//randomInteger(30)}
}

var trainingBlockSize = 1;
var sampleTrainingData = function() {
  if (TRAIN.iter % (numELBOSamples * trainingBlockSize) == 0) {
    _.extend(TRAIN, {data: _sampleTrainingData()})
  }
  _.extend(TRAIN, {iter: TRAIN.iter + 1})
  return TRAIN.data
}



// SNQ(expectation(Infer({
//   model: function() { globalStore['nh'] = 12;
//                       globalStore['nt'] = 5;
//                       model()},
//   method: 'optimize',
//   steps: 2000,
//   estimator: {ELBO: {samples: 20}},
//   optMethod: {adam: {stepSize: 0.01}},
//   verbose: true
// })))


//var trainingData = repeat(30, sampleTrainingData);

globalStore['trainingIteration'] = 0
var model2 = function() {
  if (_.has(globalStore, 'dont-train')) {
    console.log(globalStore)
  } else {
    var obs = Infer({method: 'forward', model: sampleTrainingData, samples: 1}).sample()
    //console.log(obs)
    globalStore['nh'] = obs.nh
    globalStore['nt'] = obs.nt
  }

  return model()
}


var dist = Infer({
  model: model2,
  method: 'optimize',
  steps: 10000,
  estimator: {ELBO: {samples: numELBOSamples}},
  optMethod: {adam: {stepSize: 0.005}},
  verbose: true
})


// display(getParams())

var w = getParams().recogw
var b = getParams().recogb

// display(Vector([1,12]))
var nnOutput = T.add(T.dot(w, Vector([12,5])), b)

var y = T.sigmoid(nnOutput)
// squish to (2,b)
var squishA = 2
var squishB = 50
var params = T.add(T.mul(y, squishB - squishA), squishA);

params


// globalStore['dont-train'] = true
// globalStore['nh'] = 1
// globalStore['nt'] = 12
// expectation(Infer({model: model2,
//                    method: 'optimize',
//                    samples: 10}))

//getParams()
